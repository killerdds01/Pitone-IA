{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/killerdds01/Pitone-IA/blob/main/progettoProgettoso.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cella 1: Importazioni e Configurazione Iniziale\n",
        "# Questo blocco importa tutte le librerie necessarie e configura l'ambiente di esecuzione,\n",
        "# inclusa la verifica della disponibilità di una GPU e l'impostazione del dispositivo.\n",
        "\n",
        "# Importazioni PyTorch: Componenti essenziali per la costruzione e l'addestramento di reti neurali.\n",
        "import torch\n",
        "import torch.nn as nn                  # Moduli di rete neurale (es. layer, funzioni di attivazione)\n",
        "import torch.optim as optim            # Algoritmi di ottimizzazione (es. SGD, Adam)\n",
        "import torchvision                     # Libreria per computer vision (modelli, dataset, trasformazioni)\n",
        "import torchvision.transforms as transforms # Trasformazioni di immagini per il preprocessing e data augmentation\n",
        "import torchvision.datasets as datasets # Per caricare dataset comuni, inclusi ImageFolder\n",
        "from torch.optim import lr_scheduler   # Scheduler per regolare il learning rate durante l'addestramento\n",
        "from torch.utils.data import DataLoader, random_split # Per caricare dati in batch e dividere i dataset\n",
        "\n",
        "# Importazioni per metriche e visualizzazioni: Strumenti per valutare il modello e visualizzare i risultati.\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import numpy as np                     # Per manipolare array numerici (fondamentale per PyTorch)\n",
        "import matplotlib.pyplot as plt        # Per creare grafici e visualizzazioni\n",
        "import seaborn as sns                  # Per grafici statistici più avanzati e esteticamente gradevoli\n",
        "\n",
        "# Importazioni per utilità: Funzioni ausiliari per operazioni di sistema e manipolazione dati.\n",
        "import time                            # Per misurare il tempo di esecuzione delle operazioni\n",
        "import os                              # Per interagire con il sistema operativo (es. percorsi file, creazione directory)\n",
        "import copy                            # Per creare copie profonde di oggetti (necessario per salvare i pesi del modello migliore)\n",
        "import collections                     # Per contare le occorrenze degli elementi (utile per la distribuzione delle classi)\n",
        "\n",
        "# Stampa le informazioni sull'ambiente PyTorch e GPU.\n",
        "print(f\"Pytorch Version: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# Imposta il dispositivo da utilizzare per l'addestramento: GPU (CUDA) se disponibile, altrimenti CPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Evklmqh5MD8D",
        "outputId": "3a8fe566-f430-42d6-edb9-85e316bb50e2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch Version: 2.6.0+cu124\n",
            "CUDA Available: False\n",
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cella 2: Configurazione Kaggle e Download/Decompressione Dataset\n",
        "# Questo blocco gestisce l'autenticazione con Kaggle API, il download del dataset\n",
        "# e la sua decompressione nella directory di lavoro di Colab.\n",
        "\n",
        "# Carica il file 'kaggle.json' per l'autenticazione Kaggle API.\n",
        "# Questo file contiene le tue credenziali API di Kaggle.\n",
        "from google.colab import files\n",
        "files.upload() # Si apre una finestra di dialogo per selezionare il file.\n",
        "\n",
        "# Elenca i file nella directory corrente per verificare il caricamento.\n",
        "!ls -l\n",
        "\n",
        "# Configura Kaggle API: sposta il file kaggle.json nella directory corretta e imposta i permessi.\n",
        "# Questo permette di utilizzare i comandi Kaggle CLI.\n",
        "!mkdir -p ~/.kaggle # Crea la directory .kaggle se non esiste\n",
        "!mv kaggle.json ~/.kaggle/kaggle.json # Sposta il file di credenziali\n",
        "!chmod 600 ~/.kaggle/kaggle.json # Imposta i permessi per renderlo accessibile solo all'utente\n",
        "\n",
        "# Scarica il Dataset \"Multi class garbage classification Dataset\" da Kaggle Hub.\n",
        "# L'identificatore del dataset punta a una specifica risorsa su Kaggle.\n",
        "import kagglehub\n",
        "dataset_identifier = \"vishallazrus/multi-class-garbage-classification-dataset\"\n",
        "path = kagglehub.dataset_download(dataset_identifier)\n",
        "print(\"Path to new dataset files:\", path)\n",
        "\n",
        "# Decomprimi il dataset scaricato.\n",
        "# Il file ZIP viene estratto in una directory specifica per l'organizzazione.\n",
        "zip_file_name = \"multi-class-garbage-classification-dataset.zip\"\n",
        "extraction_path = \"./garbage_dataset_with_organic\" # Cartella di destinazione per l'estrazione\n",
        "!unzip -q {zip_file_name} -d {extraction_path} # Comando unzip in modalità 'quiet'\n",
        "print(f\"Dataset decompresso in: {extraction_path}\")\n",
        "\n",
        "# Esplora la sottocartella annidata del dataset per identificare il percorso corretto dei dati.\n",
        "# Spesso i dataset Kaggle hanno una struttura di directory nidificata.\n",
        "nested_path = \"/kaggle/input/multi-class-garbage-classification-dataset/Multi class garbage classification\"\n",
        "print(f\"\\nContenuto di '{nested_path}':\")\n",
        "print(os.listdir(nested_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "VIUqbnxcMG2u",
        "outputId": "adece2ae-a93f-46c0-b92b-db5df30356e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bfc6ff3f-cbef-4f0a-b45c-dac29f40dd85\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bfc6ff3f-cbef-4f0a-b45c-dac29f40dd85\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cella 3: Caricamento e Preparazione del Dataset Rifiuti con PyTorch\n",
        "# Questo blocco definisce le trasformazioni delle immagini, rimappa le classi\n",
        "# del dataset originale alle classi target del progetto e crea i DataLoader\n",
        "# per l'addestramento, la validazione e il test.\n",
        "\n",
        "print(\"\\n<<< Caricamento e Preparazione Dataset Rifiuti per PyTorch >>>\")\n",
        "\n",
        "# Definizione del percorso base del dataset dove si trovano le immagini.\n",
        "DATA_PATH = '/kaggle/input/multi-class-garbage-classification-dataset/Multi class garbage classification'\n",
        "\n",
        "# Mappatura delle classi originali del dataset alle 5 classi finali del progetto.\n",
        "# Questo raggruppa 'paper' e 'cardboard' in 'carta' ed esclude 'metal'.\n",
        "class_mapping_original_to_final = {\n",
        "    'plastic': 0,      # Nuova classe 0: Plastica\n",
        "    'paper': 1,        # Nuova classe 1: Carta\n",
        "    'cardboard': 1,    # Mappa 'cardboard' a 'Carta'\n",
        "    'glass': 2,        # Nuova classe 2: Vetro\n",
        "    'compost': 3,      # Nuova classe 3: Organico\n",
        "    'trash': 4         # Nuova classe 4: Indifferenziato\n",
        "    # 'metal' NON è inclusa, verrà filtrata nella funzione di mappatura\n",
        "}\n",
        "\n",
        "# Definisce i nomi delle classi finali, utilizzati per etichettare i grafici e le predizioni.\n",
        "final_class_names = ['plastica', 'carta', 'vetro', 'organico', 'indifferenziato']\n",
        "num_classes = len(final_class_names) # Determina il numero totale di classi per il modello (5).\n",
        "\n",
        "# Trasformazioni delle immagini: preprocessing e data augmentation.\n",
        "# Queste trasformazioni sono applicate a ciascuna immagine prima di essere passata al modello.\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224), # Ritaglia casualmente e ridimensiona a 224x224 (data augmentation)\n",
        "        transforms.RandomHorizontalFlip(), # Riflette orizzontalmente l'immagine (data augmentation)\n",
        "        transforms.ToTensor(),             # Converte l'immagine PIL in un tensore PyTorch\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Normalizza l'immagine con media e deviazione standard di ImageNet\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(256),            # Ridimensiona l'immagine a 256x256\n",
        "        transforms.CenterCrop(224),        # Esegue un ritaglio centrale a 224x224\n",
        "        transforms.ToTensor(),             # Converte in tensore\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Normalizza\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Caricamento dei dataset RAW utilizzando ImageFolder.\n",
        "# Inizialmente, carica tutte le immagini e le loro classi originali senza trasformazioni.\n",
        "train_dataset_original = datasets.ImageFolder(os.path.join(DATA_PATH, 'train'))\n",
        "test_dataset_original = datasets.ImageFolder(os.path.join(DATA_PATH, 'test'))\n",
        "\n",
        "# Funzione per filtrare e rimappare i campioni in base alla 'class_mapping_original_to_final'.\n",
        "# Questo crea una lista di (percorso_immagine, nuova_etichetta_classe) solo per le classi incluse.\n",
        "def get_remapped_samples(original_dataset, class_mapping):\n",
        "    remapped_samples = []\n",
        "    for path, original_class_idx in original_dataset.samples:\n",
        "        original_class_name = original_dataset.classes[original_class_idx]\n",
        "        if original_class_name in class_mapping:\n",
        "            remapped_samples.append((path, class_mapping[original_class_name]))\n",
        "    return remapped_samples\n",
        "\n",
        "# Ottieni i campioni filtrati e rimappati per i set di addestramento e test.\n",
        "train_remapped_samples = get_remapped_samples(train_dataset_original, class_mapping_original_to_final)\n",
        "test_remapped_samples = get_remapped_samples(test_dataset_original, class_mapping_original_to_final)\n",
        "\n",
        "# Crea un Custom Dataset che utilizza i campioni filtrati/rimappati e applica le trasformazioni.\n",
        "class CustomRemappedDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, samples, transform=None):\n",
        "        self.samples = samples\n",
        "        self.transform = transform\n",
        "        self.classes = final_class_names # Associa i nomi delle classi finali al dataset\n",
        "        self.class_to_idx = {name: i for i, name in enumerate(final_class_names)} # Mappa nomi a indici\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.samples[idx]\n",
        "        image = datasets.folder.default_loader(path) # Carica l'immagine come PIL Image\n",
        "        if self.transform:\n",
        "            image = self.transform(image) # Applica le trasformazioni definite\n",
        "        return image, label\n",
        "\n",
        "# Inizializza i dataset finali con i campioni rimappati e le trasformazioni appropriate.\n",
        "train_dataset_full = CustomRemappedDataset(train_remapped_samples, transform=data_transforms['train'])\n",
        "test_dataset = CustomRemappedDataset(test_remapped_samples, transform=data_transforms['test'])\n",
        "\n",
        "# Suddivide il dataset di addestramento completo in set di addestramento (80%) e validazione (20%).\n",
        "train_size = int(0.8 * len(train_dataset_full))\n",
        "val_size = len(train_dataset_full) - train_size\n",
        "train_dataset, val_dataset = random_split(train_dataset_full, [train_size, val_size])\n",
        "\n",
        "# Creazione dei DataLoader: gestiscono il caricamento dei dati in batch e lo shuffling.\n",
        "BATCH_SIZE = 64     # Numero di immagini per batch\n",
        "num_workers = 2     # Numero di sottoprocessi per il caricamento dei dati (migliora le performance)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "# Stampa le dimensioni dei set e il numero di batch per verifica.\n",
        "print(f\"Dimensioni del set di addestramento: {len(train_dataset)} immagini\")\n",
        "print(f\"Dimensioni del set di validazione: {len(val_dataset)} immagini\")\n",
        "print(f\"Dimensioni del set di test: {len(test_dataset)} immagini\")\n",
        "print(f\"Numero di batch per l'addestramento: {len(train_loader)}\")\n",
        "print(f\"Numero di batch per la validazione: {len(val_loader)}\")\n",
        "print(f\"Numero di batch per il test: {len(test_loader)}\")\n",
        "\n",
        "# Controllo della distribuzione delle classi nei set di Training, Validazione e Test.\n",
        "# Questo aiuta a verificare che la rimappatura e la suddivisione siano state corrette.\n",
        "print(\"\\nConvalida conteggio immagini per le NUOVE classi (Train/Val/Test):\")\n",
        "train_class_counts = collections.Counter([train_dataset_full.samples[idx][1] for idx in train_dataset.indices])\n",
        "val_class_counts = collections.Counter([train_dataset_full.samples[idx][1] for idx in val_dataset.indices])\n",
        "test_class_counts = collections.Counter([s[1] for s in test_dataset.samples])\n",
        "\n",
        "print(\"Distribuzione classi Training (rimappate):\")\n",
        "for class_idx in sorted(train_class_counts.keys()):\n",
        "    print(f\"   {final_class_names[class_idx]}: {train_class_counts[class_idx]} immagini\")\n",
        "\n",
        "print(\"Distribuzione classi Validazione (rimappate):\")\n",
        "for class_idx in sorted(val_class_counts.keys()):\n",
        "    print(f\"   {final_class_names[class_idx]}: {val_class_counts[class_idx]} immagini\")\n",
        "\n",
        "print(\"Distribuzione classi Test (rimappate):\")\n",
        "for class_idx in sorted(test_class_counts.keys()):\n",
        "    print(f\"   {final_class_names[class_idx]}: {test_class_counts[class_idx]} immagini\")\n",
        "\n",
        "\n",
        "# --- Visualizzazione di Esempio di Immagini del Dataset ---\n",
        "# Questo blocco mostra alcune immagini con le loro etichette rimappate.\n",
        "class_names = final_class_names # Usa i nomi delle classi finali per la visualizzazione\n",
        "\n",
        "# Funzione helper per denormalizzare e mostrare un'immagine tensore.\n",
        "def imshow(img):\n",
        "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "    img = img * std + mean # Denormalizza l'immagine\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0))) # Trasponi i canali per la visualizzazione Matplotlib\n",
        "    plt.show()\n",
        "\n",
        "# Ottieni un batch di immagini dal train_loader per la visualizzazione.\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "plt.figure(figsize=(10, 5)) # Imposta la dimensione della figura\n",
        "for i in range(4): # Mostra le prime 4 immagini del batch\n",
        "    plt.subplot(1, 4, i + 1) # Crea un subplot per ciascuna immagine\n",
        "    img = images[i]\n",
        "    mean_val = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "    std_val = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "    img_denormalized = img * std_val + mean_val # Denormalizza per visualizzazione corretta\n",
        "    npimg = img_denormalized.numpy()\n",
        "\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0))) # Mostra l'immagine\n",
        "    plt.title(class_names[labels[i].item()]) # Imposta il titolo con il nome della classe\n",
        "    plt.axis('off') # Nasconde gli assi\n",
        "plt.tight_layout() # Ottimizza la disposizione dei subplot\n",
        "plt.show() # Mostra la figura\n",
        "\n",
        "# Stampa le forme dell'input e il numero di classi per la configurazione del modello.\n",
        "input_shape = (3, 224, 224) # Formato (Canali, Altezza, Larghezza) per input del modello\n",
        "print(f\"Forma dell'input per il modello (Canali, Altezza, Larghezza): {input_shape}\")\n",
        "print(f\"Numero totale di classi per il modello (DOPO raggruppamenti/esclusioni): {num_classes}\")\n",
        "print(\"\\nDataset caricato e pronto per l'addestramento del modello!\")"
      ],
      "metadata": {
        "id": "qqUjYWxaMJNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cella 4: Architettura del Modello e Funzione di Addestramento\n",
        "# Questo blocco definisce l'architettura del modello utilizzando il transfer learning con ResNet18,\n",
        "# congela i layer pre-addestrati e definisce la funzione principale per l'addestramento\n",
        "# e la valutazione del modello con Early Stopping.\n",
        "\n",
        "print(\"\\n<<< Definizione Architettura del Modello >>>\")\n",
        "\n",
        "# Carica il modello pre-addestrato ResNet18 da torchvision.\n",
        "# 'weights=torchvision.models.ResNet18_Weights.IMAGENET1K_V1' scarica i pesi pre-addestrati su ImageNet.\n",
        "model_transfer = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Sostituzione del layer finale completamente connesso (Fully Connected layer).\n",
        "# Adattiamo l'ultimo layer della ResNet18 al nostro numero specifico di classi (5 classi di rifiuti).\n",
        "num_ftrs = model_transfer.fc.in_features # Ottiene il numero di feature in input al layer FC originale\n",
        "model_transfer.fc = nn.Linear(num_ftrs, num_classes) # Sostituisce il layer FC con uno nuovo per 'num_classes' uscite\n",
        "\n",
        "# --- LOGICA DI CONGELAMENTO ROBUSTA ---\n",
        "# Congela tutti i parametri del modello base tranne l'ultimo layer FC.\n",
        "# Questo è il cuore del \"fine-tuning leggero\" o \"feature extraction\":\n",
        "# solo i pesi del nuovo layer FC verranno addestrati, mentre il resto del modello rimane fisso.\n",
        "for param in model_transfer.parameters():\n",
        "    param.requires_grad = False # Imposta requires_grad a False per congelare il layer\n",
        "for param in model_transfer.fc.parameters():\n",
        "    param.requires_grad = True # Imposta requires_grad a True solo per il nuovo layer FC, rendendolo addestrabile\n",
        "# --- FINE LOGICA DI CONGELAMENTO ROBUSTA ---\n",
        "\n",
        "# Sposta il modello sul dispositivo di calcolo (GPU o CPU) definito in precedenza.\n",
        "model_transfer = model_transfer.to(device)\n",
        "\n",
        "# Stampa la struttura del modello modificato per verifica.\n",
        "print(\"\\nModello ResNet18 caricato e modificato:\")\n",
        "print(model_transfer)\n",
        "\n",
        "# Verifica quali parametri del modello sono addestrabili.\n",
        "print(\"\\nParametri addestrabili (dovrebbe essere solo il layer fc):\")\n",
        "trainable_params_count = 0\n",
        "for name, param in model_transfer.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name) # Stampa il nome del parametro se è addestrabile\n",
        "        trainable_params_count += 1\n",
        "if trainable_params_count == 0:\n",
        "    print(\"ATTENZIONE: Nessun parametro addestrabile trovato! Questo causerà un errore di addestramento.\")\n",
        "elif trainable_params_count != 2: # Il layer FC ha solitamente 2 parametri: peso (weight) e bias\n",
        "    print(f\"ATTENZIONE: Trovati {trainable_params_count} parametri addestrabili. Ci si aspettano 2 (fc.weight, fc.bias).\")\n",
        "\n",
        "print(\"\\nModello definito e pronto per l'addestramento!\")\n",
        "\n",
        "\n",
        "# --- Funzione di addestramento e valutazione (CON Early Stopping) ---\n",
        "# Questa funzione incapsula l'intero ciclo di addestramento e validazione per più epoche.\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25, patience=10, phase_name=\"Fine-tuning\"):\n",
        "    since = time.time() # Inizia a misurare il tempo di addestramento\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict()) # Inizializza con i pesi attuali del modello (per salvare i migliori)\n",
        "    best_acc = 0.0 # Tiene traccia della migliore accuratezza di validazione trovata\n",
        "    epochs_no_improve = 0 # Contatore delle epoche senza miglioramento per l'Early Stopping\n",
        "\n",
        "    # Liste per memorizzare la loss e l'accuratezza per ogni epoca, per la visualizzazione dei grafici.\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Ogni epoca ha due fasi: 'train' (addestramento) e 'val' (validazione).\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train() # Imposta il modello in modalità addestramento (abilita dropout, batchnorm, ecc.)\n",
        "                dataloader = train_loader # Usa il DataLoader del training set\n",
        "            else:\n",
        "                model.eval()  # Imposta il modello in modalità valutazione (disabilita dropout, fissa batchnorm)\n",
        "                dataloader = val_loader # Usa il DataLoader del validation set\n",
        "\n",
        "            running_loss = 0.0      # Inizializza la loss cumulativa per l'epoca\n",
        "            running_corrects = 0    # Inizializza il conteggio delle predizioni corrette cumulative\n",
        "\n",
        "            # Iterazione su tutti i batch del DataLoader per la fase corrente.\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs = inputs.to(device) # Sposta input sul dispositivo (GPU/CPU)\n",
        "                labels = labels.to(device) # Sposta etichette sul dispositivo\n",
        "\n",
        "                optimizer.zero_grad() # Azzera i gradienti per evitare accumulazioni da batch precedenti\n",
        "\n",
        "                # Calcolo del forward pass, loss e backward pass (solo in fase di addestramento).\n",
        "                with torch.set_grad_enabled(phase == 'train'): # Abilita/Disabilita calcolo gradienti\n",
        "                    outputs = model(inputs) # Esegue il forward pass\n",
        "                    _, preds = torch.max(outputs, 1) # Ottiene le predizioni (indice della classe con prob. maggiore)\n",
        "                    loss = criterion(outputs, labels) # Calcola la loss\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward() # Calcola i gradienti della loss rispetto ai parametri del modello\n",
        "                        optimizer.step() # Aggiorna i pesi del modello usando l'ottimizzatore\n",
        "\n",
        "                # Aggiorna le statistiche cumulative per l'epoca corrente.\n",
        "                running_loss += loss.item() * inputs.size(0) # 'loss.item()' è la loss media per batch, la moltiplichiamo per la dimensione del batch\n",
        "                running_corrects += torch.sum(preds == labels.data) # Conta le predizioni corrette\n",
        "\n",
        "            # Calcola la loss e l'accuratezza medie per l'intera epoca.\n",
        "            epoch_loss = running_loss / len(dataloader.dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloader.dataset) # .double() per divisione accurata\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # Logica specifica per la fase di validazione.\n",
        "            if phase == 'val':\n",
        "                scheduler.step(epoch_loss) # Aggiorna lo scheduler del learning rate in base alla loss di validazione\n",
        "                val_losses.append(epoch_loss) # Aggiunge la loss di validazione alla lista\n",
        "                val_accuracies.append(epoch_acc.item()) # Aggiunge l'accuratezza di validazione alla lista\n",
        "\n",
        "                # Logica di Early Stopping: Controlla se l'accuratezza di validazione è migliorata.\n",
        "                if epoch_acc > best_acc: # Se l'accuratezza attuale è migliore della migliore finora\n",
        "                    best_acc = epoch_acc # Aggiorna la migliore accuratezza\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict()) # Salva i pesi del modello corrispondenti\n",
        "                    epochs_no_improve = 0 # Reset del contatore perché c'è stato un miglioramento\n",
        "                else:\n",
        "                    epochs_no_improve += 1 # Incrementa il contatore se non c'è stato miglioramento\n",
        "\n",
        "            # Logica specifica per la fase di addestramento.\n",
        "            else: # Corrisponde a 'phase == 'train''\n",
        "                train_losses.append(epoch_loss) # Aggiunge la loss di addestramento\n",
        "                train_accuracies.append(epoch_acc.item()) # Aggiunge l'accuratezza di addestramento\n",
        "\n",
        "        # Controllo della condizione di Early Stopping dopo le fasi di train e val di ogni epoca.\n",
        "        if epochs_no_improve >= patience: # Se il contatore supera la pazienza definita\n",
        "            print(f\"Early stopping triggerato: L'accuratezza di validazione non è migliorata per {patience} epoche.\")\n",
        "            break # Esce dal ciclo principale delle epoche (ferma l'addestramento)\n",
        "\n",
        "        print() # Linea vuota per una migliore formattazione dell'output tra le epoche\n",
        "\n",
        "    time_elapsed = time.time() - since # Calcola il tempo totale impiegato per l'addestramento\n",
        "    print(f'Addestramento completato in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Migliore accuratezza di validazione: {best_acc:.4f}')\n",
        "\n",
        "    model.load_state_dict(best_model_wts) # Carica i pesi del modello che ha dato la migliore accuratezza di validazione.\n",
        "                                          # Questo garantisce che il modello restituito sia il \"migliore\" per la generalizzazione.\n",
        "\n",
        "    # --- Plot delle curve di Loss e Accuratezza ---\n",
        "    # Visualizza l'andamento della loss e dell'accuratezza nel tempo per monitorare l'addestramento.\n",
        "    plt.figure(figsize=(12, 5)) # Imposta la dimensione della figura\n",
        "\n",
        "    # Grafico della Loss\n",
        "    plt.subplot(1, 2, 1) # Crea il primo subplot (1 riga, 2 colonne, primo grafico)\n",
        "    plt.plot(train_losses, label='Train Loss') # Curva della loss di addestramento\n",
        "    plt.plot(val_losses, label='Val Loss')     # Curva della loss di validazione\n",
        "    plt.title(f'Curva di Loss ({phase_name})') # Titolo del grafico con il nome della fase\n",
        "    plt.xlabel('Epoche') # Etichetta asse X\n",
        "    plt.ylabel('Loss')   # Etichetta asse Y\n",
        "    plt.legend()         # Mostra la legenda per identificare le curve\n",
        "    plt.grid(True)       # Abilita la griglia\n",
        "\n",
        "    # Grafico dell'Accuratezza\n",
        "    plt.subplot(1, 2, 2) # Crea il secondo subplot\n",
        "    plt.plot(train_accuracies, label='Train Accuracy') # Curva dell'accuratezza di addestramento\n",
        "    plt.plot(val_accuracies, label='Val Accuracy')     # Curva dell'accuratezza di validazione\n",
        "    plt.title(f'Curva di Accuratezza ({phase_name})') # Titolo del grafico\n",
        "    plt.xlabel('Epoche')\n",
        "    plt.ylabel('Accuratezza')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout() # Regola automaticamente i parametri del subplot per un layout compatto\n",
        "    plt.show() # Mostra la figura con i grafici\n",
        "\n",
        "    # Restituisce il modello addestrato e la storia delle metriche.\n",
        "    return model, train_losses, val_losses, train_accuracies, val_accuracies"
      ],
      "metadata": {
        "id": "j2nCicMuMLX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cella 5: Esecuzione Addestramento (Fine-tuning Leggero) e Salvataggio Modello\n",
        "# Questo blocco avvia la fase di addestramento \"Fine-tuning Leggero\" e, al termine,\n",
        "# salva il modello con i pesi migliori (determinati dall'Early Stopping) nella sessione di Colab.\n",
        "\n",
        "print(\"\\n<<< Avvio Addestramento del Modello (Fase di Fine-tuning Leggero) >>>\")\n",
        "\n",
        "num_epochs_finetune = 60 # Numero massimo di epoche per questa fase\n",
        "\n",
        "# --- Definizione della funzione di perdita (Loss Function) ---\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# --- Definizione dell'ottimizzatore ---\n",
        "# Aggiorna SOLO i parametri che hanno requires_grad=True (che ora sarà SOLO il layer fc dalla Cella 4)\n",
        "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model_transfer.parameters()), lr=0.001)\n",
        "\n",
        "# --- Definizione dello scheduler per il learning rate ---\n",
        "scheduler_ft = lr_scheduler.ReduceLROnPlateau(optimizer_ft, mode='min', patience=7, factor=0.1, min_lr=1e-08)\n",
        "\n",
        "print(f\"\\n<<< Avvio Fine-tuning STANDARD per {num_epochs_finetune} epoche >>>\")\n",
        "print(f\"Learning Rate iniziale: {optimizer_ft.param_groups[0]['lr']:.0e}\")\n",
        "print(\"Parametri addestrabili durante il Fine-tuning Standard (dovrebbe essere solo fc):\")\n",
        "trainable_params_count_check = 0\n",
        "for name, param in model_transfer.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)\n",
        "        trainable_params_count_check += 1\n",
        "if trainable_params_count_check == 0:\n",
        "    print(\"ATTENZIONE: L'ottimizzatore non troverà parametri addestrabili. Controlla la Cella 3!\")\n",
        "elif trainable_params_count_check != 2: # fc.weight and fc.bias\n",
        "    print(f\"ATTENZIONE: Trovati {trainable_params_count_check} parametri addestrabili. Ci si aspettano 2 (fc.weight, fc.bias).\")\n",
        "\n",
        "# --- Esegui l'addestramento (SOLO Fine-tuning STANDARD - Fase 1) ---\n",
        "# Pazienza per la prima fase: attendiamo 10 epoche senza miglioramento prima di fermarci\n",
        "print(\"\\n<<< Fase 1: Fine-tuning Leggero (Solo layer FC) >>>\")\n",
        "model_fine_tuned_light, train_loss_history_ft, val_loss_history_ft, train_acc_history_ft, val_acc_history_ft = train_model(\n",
        "    model_transfer, criterion, optimizer_ft, scheduler_ft, num_epochs=num_epochs_finetune, patience=10, phase_name=\"Fine-tuning Leggero\"\n",
        ")\n",
        "\n",
        "# --- Salva il modello con i pesi migliori della fase di fine-tuning leggero ---\n",
        "# Questo sarà il modello con l'accuratezza di circa 82.45%\n",
        "torch.save(model_fine_tuned_light.state_dict(), 'best_model_finetuned_light.pth')\n",
        "print(\"\\nModello 'best_model_finetuned_light.pth' salvato con successo nella sessione di Colab!\")\n",
        "print(\"\\nFase 1 (Fine-tuning Leggero) completato!\")"
      ],
      "metadata": {
        "id": "d8hCo1VOMNui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cella 6: Valutazione Finale sul Test Set e Analisi Dettagliate\n",
        "# Questo blocco carica il modello salvato e lo valuta sul set di test finale,\n",
        "# fornendo metriche di performance come Loss, Accuratezza, Matrice di Confusione\n",
        "# e un Report di Classificazione dettagliato.\n",
        "\n",
        "print(\"\\n<<< Avvio Valutazione Finale sul Test Set >>>\")\n",
        "\n",
        "# Carica il modello migliore salvato dalla fase di fine-tuning leggero.\n",
        "# Assicurati che l'architettura del modello sia la stessa di quando è stato salvato.\n",
        "# Per semplicità, riutilizziamo 'model_transfer' e gli carichiamo i pesi.\n",
        "model_final_eval = model_transfer # Re-usa l'architettura già definita\n",
        "model_final_eval.load_state_dict(torch.load('best_model_finetuned_light.pth'))\n",
        "model_final_eval.to(device) # Assicurati che il modello sia sul dispositivo corretto\n",
        "model_final_eval.eval() # Imposta il modello in modalità valutazione (disabilita dropout, batchnorm, ecc.)\n",
        "\n",
        "print(\"Modello 'best_model_finetuned_light.pth' caricato con successo per la valutazione.\")\n",
        "\n",
        "# Esegui la valutazione sul test loader.\n",
        "running_loss = 0.0\n",
        "running_corrects = 0\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad(): # Disabilita il calcolo dei gradienti per la valutazione (risparmia memoria e tempo)\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model_final_eval(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        all_labels.extend(labels.cpu().numpy()) # Raccogli tutte le etichette reali\n",
        "        all_preds.extend(preds.cpu().numpy())   # Raccogli tutte le predizioni del modello\n",
        "\n",
        "test_loss = running_loss / len(test_loader.dataset)\n",
        "test_accuracy = running_corrects.double() / len(test_loader.dataset)\n",
        "\n",
        "print(\"\\nRisultati sul Test Set:\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
        "\n",
        "print(\"\\nValutazione sul Test Set completata!\")\n",
        "\n",
        "# --- Visualizzazione Matrice di Confusione e Report di Classificazione ---\n",
        "# Questi strumenti forniscono una valutazione dettagliata delle performance del modello per ogni classe.\n",
        "\n",
        "print(\"\\n<<< Analisi delle Performance Dettagliate >>>\")\n",
        "\n",
        "# Calcola la Matrice di Confusione\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=final_class_names, yticklabels=final_class_names)\n",
        "plt.title('Matrice di Confusione')\n",
        "plt.xlabel('Classe Predetta')\n",
        "plt.ylabel('Classe Reale')\n",
        "plt.show()\n",
        "\n",
        "# Genera il Report di Classificazione\n",
        "# Questo report include precisione, richiamo, F1-score e supporto per ciascuna classe.\n",
        "class_report = classification_report(all_labels, all_preds, target_names=final_class_names)\n",
        "print(\"\\nReport di Classificazione sul Test Set:\")\n",
        "print(class_report)\n",
        "\n",
        "print(\"\\nAnalisi completata!\")"
      ],
      "metadata": {
        "id": "YCSzDPTUMT9r"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOP5WK2C4mVXJiSnCxkMFE7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}